## ğŸ§  Image Classification using SVM (with PCA Dimensionality Reduction)

### ğŸ“Œ Project Overview

This project demonstrates **image classification** using **Support Vector Machine (SVC)** combined with **Principal Component Analysis (PCA)** for dimensionality reduction.
The main goal is to classify images (e.g., handwritten letters, faces, or objects) efficiently without deep learning, while maintaining reasonable accuracy and low memory usage.

---

### ğŸš€ Features

* Loads and preprocesses image data
* Reduces dimensionality using **PCA**
* Trains an **SVC (Support Vector Classifier)** with optimized parameters
* Evaluates model performance with accuracy, precision, recall, and F1-score
* Includes an optional **GridSearchCV** step for hyperparameter tuning

---

### ğŸ§© Project Workflow

1. **Data Preparation**

   * Images are resized to `(64Ã—64)` and converted into feature vectors.
   * Labels are encoded numerically.

2. **Feature Scaling**

   * Standardized using `StandardScaler` to normalize pixel intensity.

3. **Dimensionality Reduction**

   * `PCA` is applied to reduce the number of features from 12,288 â†’ 200 (or other configurable values).

4. **Model Training**

   * `SVC` is trained using the RBF kernel (best found using GridSearch).

5. **Model Evaluation**

   * Performance is measured using `classification_report` and accuracy metrics.

---

### âš™ï¸ Optional: Hyperparameter Optimization

You can use `GridSearchCV` to automatically find the best kernel, C, and gamma values.

---

### ğŸ“Š Example Results

| Metric    | Score |
| :-------- | :---- |
| Accuracy  | 0.65  |
| Precision | 0.64  |
| Recall    | 0.66  |
| F1-score  | 0.65  |

---

### ğŸ§¾ Requirements

Install dependencies using:

```bash
pip install numpy pandas scikit-learn opencv-python tqdm matplotlib
```

---

### ğŸ—‚ï¸ Folder Structure

```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ test/
â”œâ”€â”€ main.ipynb
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

### ğŸ’¡ Future Improvements

* Apply **HOG features** for better feature extraction
* Experiment with **CNN models (e.g., TensorFlow/Keras)**
* Try larger PCA components for improved accuracy
* Add visualizations for confusion matrix and PCA variance

